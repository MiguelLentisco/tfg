% !TeX root = ../libro.tex
% !TeX encoding = utf8
%
%*******************************************************
% Summary
%*******************************************************

\selectlanguage{english}
\chapter*{Summary}\label{ch:summary}
%\addcontentsline{toc}{chapter}{Summar}

The main goal of this project is to tackle research problems where there has been little research on, focusing on the domain of time series and solving these problems using models based on LSTM neural networks architectures.

First, we present a brief background of the project with an introduction to its basis, the motivation that led to its realization, objectives to accomplish and the structure of this document.

The first part is formed by the basic concepts used in the development of this project: Deep Learning, time series and metrics. The basics of Deep Learning starts with a short tour through the neural networks history with the aim to learn about its origins, leading to the most basic but functional neural network: the feed-forward neural network. We explain in detail how this model work, allowing us to understand the majority of neural networks models used nowadays as these networks share the fundamentals to a large degree of similarity. Finally, we list a few of the most well-known neural network architectures, focusing on the LSTM cells. This type of neural network tries to learn certain time-dependent patterns in the data, being perfectly suited for dealing with time series. This goal is accomplished through the use of information obtained of the past inputs that flows into the neuron like a feedback connection, providing it with a context that can be utilized for a better prediction of the current input.

Regarding the time series, we present the main results of the current research on the time series analysis with its mathematical foundation. First, we explore the probabilistic theory that includes the stochastic processes, successions of random variables, and the stationary processes, which are processes whose distribution does not change with a temporal shift. Then we study the lineal models like ARMA that are used for time series analysis, and its applications with the time series decomposition (like STL decomposition) or the time series \emph{differencing}. Combining either of these methods with the ARMA model leads us into the ARIMA and SARIMA models. We also introduce and explain a few techniques related to the process of time series \emph{discretization} such as the SAX method or a method based on the $k$-means clustering algorithm.

In the last section of this part we make a quick review of the metrics that we are going to use to validate the models developed in the project: for classification problems the accuracy, F-score and the precision-recall curves and for regression the usual error metrics like mean squared error or mean absolute error.

The first part of this project addresses the problem of model selection in classification tasks, that is classically done with the cross-validation and the hold-out-test validation. We study a new heuristic called \emph{Perturbation Validation} that does not relay on a train/test partition as the classical selection, but introduces tiny perturbations into the labels of the dataset and measures how the model responses to these changes. We study and explain in depth how it works, what it measures, how we interpret its value and how can it be useful. In order to confirm this, we experiment with several machine learning models, including a LSTM neural network, in a big repository of diverse time series datasets with both model and hyper-parameters selection. We analyze in detail the results to prove the effectiveness of this heuristic, showing that it can contribute to the model selection problem.

In the second and last part we address the anomaly detection problem: detecting atypical behavior in time series. We discuss the big obstacles in this type of problems: the lack of datasets with labeled data, mainly used in the training of models based on supervised learning; and the models developed being too specific for the task they are solving thus they can not be deployed in other areas. We provide a simple but useful model based on LSTM architecture that can detect several types of anomalies, provided a well-known pattern in the time series. We also present various methods to modify the normal series in order to create artificially samples of anomalies that can be used, for example, to validate our model. We evaluate the detector and the methods using them with both a real and synthetic dataset, analyzing the performance of the detector and the quality of the perturbations.

Also, we have included two appendices regarding the documentation of the main classes, methods and functions; and diverse information about the implemented software, such as the languages (mostly \emph{Python}) and the packages used.

\paragraph{KEYWORDS:}
\begin{itemize*}[label=,itemsep=1em,itemjoin=\hspace{1em}]
  \item neural networks
  \item LSTM
  \item time series
  \item model selection
  \item validation
  \item hyper-parameters selection
  \item anomaly detection
  \item detector
  \item perturbation
\end{itemize*}

% Al finalizar el resumen en inglés, volvemos a seleccionar el idioma español para el documento
\selectlanguage{spanish}
\endinput
